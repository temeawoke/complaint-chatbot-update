# complaint-chatbot-
this repo is mainly for a complaint-answering chatbot and you want clarity and ease of understanding for users or collaborators, go with:

# ğŸ—£ï¸ Complaint-Answering Chatbot using Retrieval-Augmented Generation (RAG)

This project implements a complaint-answering chatbot using **Retrieval-Augmented Generation (RAG)**. It is built on top of the **Consumer Financial Protection Bureau (CFPB)** complaint dataset, and involves cleaning, filtering, and preparing consumer complaint narratives for downstream NLP tasks.

---

## ğŸ“ Project Structure
complaint-chatbot/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original CFPB dataset
â”‚ â”œâ”€â”€ processed/ # Cleaned & filtered data
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ 1.0-eda.ipynb # Exploratory Data Analysis
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ eda.py # EDA script (optional)
â”‚ â”œâ”€â”€ preprocessing.py # Text cleaning & normalization
â”œâ”€â”€ .github/
â”‚ â””â”€â”€ workflows/
â”‚ â””â”€â”€ ci.yml # CI setup with GitHub Actions
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md

---

## âœ… Project Tasks Completed

### 1. ğŸ“¥ Dataset Loading
- Loaded the full CFPB complaint dataset (~1M+ rows).
- Saved the original file to `data/raw/complaints.csv`.

### 2. ğŸ“Š Exploratory Data Analysis (EDA)
- Investigated missing values, top products/issues, complaint trends over time.
- Analyzed narrative lengths and distribution.
- Created bar plots and histograms using Seaborn/Matplotlib.

### 3. ğŸ” Dataset Filtering
- Included only complaints with non-empty `Consumer complaint narrative`.
- Focused on **five product categories**:
  - Credit card
  - Personal loan
  - Buy Now, Pay Later (BNPL)
  - Savings account
  - Money transfers
- Removed duplicates and irrelevant rows.
- Saved filtered data to: `data/processed/filtered_five_products.csv`

### 4. ğŸ§¼ Text Cleaning & Normalization
Performed the following preprocessing steps:
- Lowercased all narratives.
- Removed digits, special characters, and boilerplate phrases (e.g., â€œI am writing to file a complaintâ€).
- Expanded contractions (e.g., â€œcanâ€™tâ€ â†’ â€œcannotâ€).
- Removed stopwords and performed lemmatization using `spaCy`.

Final cleaned data saved to:  
`data/processed/final_cleaned_complaints.csv`

---

## ğŸ”„ CI/CD

Set up continuous integration using **GitHub Actions**:
- Workflow path: `.github/workflows/ci.yml`
- Performs linting with `flake8`, installs dependencies, and runs tests using `pytest`.

---

## ğŸ§  Next Steps (RAG Pipeline)
- Chunk and embed the cleaned narratives using a sentence transformer (e.g., `all-MiniLM-L6-v2`)
- Store vectors in a FAISS or Chroma vector database
- Use a retriever + generator setup (e.g., Hugging Face pipeline) to answer user queries based on similar complaints.

---

## ğŸ“¦ Requirements

Install dependencies:

```bash
pip install -r requirements.txt